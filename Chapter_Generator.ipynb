{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP2O2PXjMKt47tm1yfPnIrr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/richieri/notebooks/blob/main/Chapter_Generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The idea\n",
        "\n",
        "Extract possible chapters from subtitles of a video. For the purporse of this colab, we are going to use the \"Machine Learning for Everybody\" from freeCodeCamp.org:\n",
        "\n",
        "https://www.youtube.com/watch?v=i_LwzRVP7bg\n",
        "\n",
        "# How to use it\n",
        "\n",
        "1.   Upload your VTT caption file to the root of your colab environment with the name \"captions.vtt\"\n",
        "2.   Run the code :)\n",
        "\n",
        "# How to get a captions.vtt file\n",
        "\n",
        "If you don't have the captions file yet, you can generate them at https://savesubs.com/ . Got to their sites, paste the youtube video URL in the main box and ask for download.\n",
        "\n",
        "After generating it, Savesubs will give a few different formats of subtitles, pick VTT.\n",
        "\n",
        "File format must be something like this:\n",
        "\n",
        "```\n",
        "WEBVTT\n",
        "\n",
        "00:00:00.000 --> 00:00:06.000\n",
        "Kylie Ying has worked at many interesting places such as MIT, CERN, and Free Code Camp.\n",
        "\n",
        "00:00:06.000 --> 00:00:10.880\n",
        "She's a physicist, engineer, and basically a genius. And now she's going to teach you\n",
        "\n",
        "00:00:10.880 --> 00:00:14.720\n",
        "about machine learning in a way that is accessible to absolute beginners.\n",
        "\n",
        "00:00:15.280 --> 00:00:21.600\n",
        "What's up you guys? So welcome to Machine Learning for Everyone. If you are someone who\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "# Author\n",
        "\n",
        "Ronaldo Richieri\n",
        "\n",
        "https://github.com/richieri"
      ],
      "metadata": {
        "id": "S5YouJJMAoTO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code explained\n",
        "\n",
        "Install required dependencies"
      ],
      "metadata": {
        "id": "O_LTVc-wAMKK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4OdfpbsgQX0"
      },
      "outputs": [],
      "source": [
        "!pip install langchain openai tiktoken"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import libraries and set API Key"
      ],
      "metadata": {
        "id": "BfcVjOAJAZ34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import OpenAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain import PromptTemplate\n",
        "\n",
        "import os\n",
        "\n",
        "openai_api_key = \"PLACE YOUR OPEN AI API KEY HERE\""
      ],
      "metadata": {
        "id": "oTOKeDcvgZ92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ingest the captions file to a \"captions\" variable"
      ],
      "metadata": {
        "id": "pGNxCI5-Ainc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "video_captions = './captions.vtt'\n",
        "\n",
        "with open(video_captions, 'r') as file:\n",
        "    captions = file.read()"
      ],
      "metadata": {
        "id": "6atua9UFgdwH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the captions file in multiple chunks that will be stuffed into the prompt to be sent to OpenAI. This is required because our calls to OpenAI have a limit of words (tokens to be more accurated) that can be sent.\n",
        "Which model has its own limit. In this case, we are working with a of 4096 tokens.\n",
        "\n",
        "We split in multiple documents."
      ],
      "metadata": {
        "id": "_0MjASVfB4TY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
        "\n",
        "llm.get_num_tokens(captions)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\"], chunk_size=5000, chunk_overlap=400)\n",
        "\n",
        "docs = text_splitter.create_documents([captions])\n",
        "\n",
        "num_docs = len(docs)\n",
        "num_tokens_first_doc = llm.get_num_tokens(docs[0].page_content)\n",
        "print (f\"Now we have {num_docs} documents and the first one has {num_tokens_first_doc} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hmf1QuShBt79",
        "outputId": "5fa56942-9c38-4d62-aaa2-480faeccf926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now we have 50 documents and the first one has 1554 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the prompt"
      ],
      "metadata": {
        "id": "hc9slL_-CjSC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"\"\"\n",
        "Summarize the following SBV subtitles from a video in one single topic and add the time it started and ended, returning the output in only this JSON format {{\"start\":\"00:00:00\",\"end\":\"00:00:00\",\"topic\":\"...\"}}:\n",
        "{doc}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"doc\"],\n",
        "    template=template\n",
        ")\n"
      ],
      "metadata": {
        "id": "mIKFRn4Igs_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Send each chuk (stuffed into the prompt) to OpenAI and get the results"
      ],
      "metadata": {
        "id": "rWwOuT_mCrPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in docs:\n",
        "  # print(\"This doc\",doc.page_content)\n",
        "  summary_prompt = prompt.format(doc=doc.page_content)\n",
        "  num_tokens = llm.get_num_tokens(summary_prompt)\n",
        "#  print (f\"This prompt + doc has {num_tokens} tokens\")\n",
        "  summary = llm(summary_prompt)\n",
        "  print (summary.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzQtE9ZqCpnH",
        "outputId": "3d4bcf14-9e8f-47dc-f69f-a6883af510bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.7 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"start\":\"00:00:00\",\"end\":\"00:04:23.600\",\"topic\":\"Introduction to Machine Learning and Using the UCI Machine Learning Repository\"}\n",
            "{\"start\":\"00:04:00.960\",\"end\":\"00:09:01.360\",\"topic\":\"Pandas and Data Frames\"}\n",
            "{\"start\":\"00:08:43.360\",\"end\":\"00:13:07.440\",\"topic\":\"Machine Learning and its Types\"}\n",
            "{\"start\":\"00:12:48.400\",\"end\":\"00:17:19.680\",\"topic\":\"Types of Data and One Hot Encoding\"}\n",
            "{\"start\":\"00:17:02.080\",\"end\":\"00:21:23.760\",\"topic\":\"Supervised Learning and Model Evaluation\"}\n",
            "{\"start\":\"00:21:04.240\",\"end\":\"00:25:45.920\",\"topic\":\"Supervised Learning and Model Training\"}\n",
            "{\"start\":\"00:25:25.680\",\"end\":\"00:30:11.360\",\"topic\":\"Loss Functions and Performance Measures\"}\n",
            "{\"start\":\"00:29:47.840\",\"end\":\"00:34:34.640\",\"topic\":\"Measuring Model Performance and Data Visualization\"}\n",
            "{\"start\":\"00:34:11.200\",\"end\":\"00:39:20.400\",\"topic\":\"Data Scaling and Stacking\"}\n",
            "{\"start\":\"00:38:58.400\",\"end\":\"00:44:23.120\",\"topic\":\"Oversampling and balancing training data\"}\n",
            "{\"start\":\"00:43:59.680\",\"end\":\"00:49:25.360\",\"topic\":\"KNN or K Nearest Neighbors Algorithm\"}\n",
            "{\"start\":\"00:49:03.520\",\"end\":\"00:54:11.880\",\"topic\":\"K Nearest Neighbors\"}\n",
            "{\"start\":\"00:53:43.920\",\"end\":\"00:58:20.440\",\"topic\":\"Classification Report and Metrics\"}\n",
            "{\"start\":\"00:57:55.640\",\"end\":\"01:02:58.920\",\"topic\":\"Naive Bayes and Bayes Rule\"}\n",
            "{\"start\":\"01:02:36.920\",\"end\":\"01:07:16.160\",\"topic\":\"Bayes Rule and Probability Calculation\"}\n",
            "{\"start\":\"01:06:52.000\",\"end\":\"01:12:07.920\",\"topic\":\"Bayes Rule and Naive Bayes Classification\"}\n",
            "{\"start\":\"01:11:48.800\",\"end\":\"01:16:39.440\",\"topic\":\"Naive Bayes Classification\"}\n",
            "{\"start\":\"01:16:14.720\",\"end\":\"01:21:30.240\",\"topic\":\"Classification and Regression Models\"}\n",
            "{\"start\":\"01:21:10.000\",\"end\":\"01:26:44.480\",\"topic\":\"Logistic Regression\"}\n",
            "{\"start\":\"01:26:19.120\",\"end\":\"01:31:38.560\",\"topic\":\"Logistic Regression and Support Vector Machines\"}\n",
            "{\"start\":\"01:31:09.040\",\"end\":\"01:36:41.600\",\"topic\":\"Support Vector Machines (SVMs)\"}\n",
            "{\"start\":\"01:36:16.080\",\"end\":\"01:40:51.840\",\"topic\":\"Support Vector Machines (SVMs) and Neural Networks\"}\n",
            "{\"start\":\"01:40:28.880\",\"end\":\"01:45:12.480\",\"topic\":\"Neural Network Training and Activation Functions\"}\n",
            "{\"start\":\"01:44:39.680\",\"end\":\"01:49:08.000\",\"topic\":\"Gradient Descent and Back Propagation in Neural Networks\"}\n",
            "{\"start\":\"01:48:49.360\",\"end\":\"01:53:42.720\",\"topic\":\"Creating a Neural Net Model in TensorFlow\"}\n",
            "{\"start\":\"01:53:23.520\",\"end\":\"01:58:15.760\",\"topic\":\"Training a Neural Network Model with TensorFlow\"}\n",
            "{\"start\":\"01:57:51.120\",\"end\":\"02:03:34.960\",\"topic\":\"Training a Neural Network Model\"}\n",
            "{\"start\":\"02:03:15.280\",\"end\":\"02:08:20.240\",\"topic\":\"Training and evaluating a model for image classification\"}\n",
            "{\"start\":\"02:07:58.160\",\"end\":\"02:12:55.040\",\"topic\":\"Classification and Regression Models\"}\n",
            "{\"start\":\"02:12:29.280\",\"end\":\"02:17:38.400\",\"topic\":\"Linear Regression and Residuals\"}\n",
            "{\"start\":\"02:17:18.960\",\"end\":\"02:22:49.600\",\"topic\":\"Linear Regression and its Assumptions\"}\n",
            "{\"start\":\"02:22:25.680\",\"end\":\"02:27:33.280\",\"topic\":\"Linear Regression Model Evaluation Techniques\"}\n",
            "{\"start\":\"02:27:10.560\",\"end\":\"02:32:19.920\",\"topic\":\"Different types of error metrics in regression\"}\n",
            "{\"start\":\"02:32:00.720\",\"end\":\"02:36:42.160\",\"topic\":\"Linear Regression and Evaluating Models\"}\n",
            "{\"start\":\"02:36:15.600\",\"end\":\"02:41:19.440\",\"topic\":\"Importing and Manipulating Data in Python\"}\n",
            "{\"start\":\"02:41:00.160\",\"end\":\"02:46:28.720\",\"topic\":\"Data Analysis and Splitting\"}\n",
            "{\"start\":\"02:46:08.160\",\"end\":\"02:51:48.400\",\"topic\":\"Linear Regression with One Dimensional Data\"}\n",
            "{\"start\":\"02:51:21.920\",\"end\":\"02:57:06.800\",\"topic\":\"Linear Regression and Neural Networks for Regression\"}\n",
            "{\"start\":\"02:56:37.120\",\"end\":\"03:01:54.480\",\"topic\":\"Using a neural net to predict temperature data\"}\n",
            "{\"start\":\"03:01:18.640\",\"end\":\"03:07:11.280\",\"topic\":\"Comparing Mean Squared Error of Linear Regression and Neural Net Models\"}\n",
            "{\"start\":\"03:06:41.760\",\"end\":\"03:12:34.880\",\"topic\":\"Supervised Learning: Linear Regression and Neural Networks\"}\n",
            "{\"start\":\"03:12:12.880\",\"end\":\"03:17:21.200\",\"topic\":\"Unsupervised Learning and K Means Clustering\"}\n",
            "{\"start\":\"03:16:54.400\",\"end\":\"03:22:19.200\",\"topic\":\"K-means Clustering\"}\n",
            "{\"start\":\"03:21:59.840\",\"end\":\"03:23:19.200\",\"topic\":\"Unsupervised Learning: Clustering and Dimensionality Reduction\"}\n",
            "{\"start\":\"03:26:53.840\",\"end\":\"03:32:00.960\",\"topic\":\"Principal Component Analysis (PCA)\"}\n",
            "{\"start\":\"03:31:42.080\",\"end\":\"03:36:29.120\",\"topic\":\"Principal Component Analysis (PCA) and Unsupervised Learning\"}\n",
            "{\"start\":\"03:36:00.960\",\"end\":\"03:41:08.640\",\"topic\":\"Using Pandas and Seaborn for Data Visualization and Clustering\"}\n",
            "{\"start\":\"03:40:40.960\",\"end\":\"03:46:25.120\",\"topic\":\"K Means Clustering\"}\n",
            "{\"start\":\"03:46:05.120\",\"end\":\"03:51:07.200\",\"topic\":\"Dimension Reduction with K Means and PCA\"}\n",
            "{\"start\":\"03:50:40.400\",\"end\":\"03:53:50.560\",\"topic\":\"Using k means dot labels for unsupervised learning and plotting the results with PCA dimensions.\"}\n"
          ]
        }
      ]
    }
  ]
}